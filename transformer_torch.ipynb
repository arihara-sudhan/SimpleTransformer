{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5890e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a729b9",
   "metadata": {},
   "source": [
    "# ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e490034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hidden_dim)\n",
    "        self.layers = nn.ModuleList([nn.TransformerEncoderLayer(hidden_dim, num_heads) \n",
    "                                     for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = x + self.pos_embedding(positions)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04196bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 32])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 100\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "encoder = TransformerEncoder(input_dim, hidden_dim, num_layers, num_heads)\n",
    "x = torch.randint(0, input_dim, (5, 10))\n",
    "output = encoder(x)\n",
    "print(output.shape) # should be (5, 10, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fa92d4",
   "metadata": {},
   "source": [
    "# nn.Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "976b4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.1586e-01,  1.4418e-01,  2.4824e-01,  7.9643e-01, -1.1111e+00,\n",
      "          -1.7674e+00,  1.3876e+00,  2.7908e-01,  1.3656e-01,  2.5834e-03,\n",
      "          -1.8136e+00, -1.9596e-02,  3.0940e-01,  9.6444e-01, -9.2067e-01,\n",
      "           9.8577e-02, -3.1250e-01, -1.9562e-01, -5.6895e-01, -2.4601e-02,\n",
      "          -1.0320e+00,  8.2333e-01, -4.8053e-01, -7.8006e-01,  3.1310e-02,\n",
      "          -2.4122e-01, -7.7215e-01, -1.6397e-01,  1.0781e+00,  1.0855e+00,\n",
      "          -1.1037e+00,  3.6565e-01, -1.2201e+00,  9.8392e-01,  2.1615e-01,\n",
      "           1.7461e+00, -2.7702e-01, -3.6400e-01,  1.8724e+00, -8.9769e-01,\n",
      "           1.9036e-01, -7.8654e-02, -4.3329e-01, -6.6862e-01, -1.7167e+00,\n",
      "          -1.4221e-01,  8.0571e-01, -1.5285e+00, -1.4034e+00, -5.0367e-02,\n",
      "          -5.0362e-01,  1.0217e+00, -1.7950e-01, -5.6588e-01,  1.5529e-01,\n",
      "           1.6634e+00, -6.0327e-01, -1.0066e-01, -2.0894e+00,  1.2368e+00,\n",
      "           7.1615e-01,  5.4580e-01,  3.2003e-01,  8.7431e-01, -8.3630e-01,\n",
      "           7.3131e-01,  1.2384e-01, -1.3560e+00, -5.7028e-01, -1.0656e+00,\n",
      "           3.5435e-01,  1.1634e+00,  5.1325e-01,  4.5481e-01, -4.2041e-01,\n",
      "          -1.3733e+00,  1.0272e-01,  1.0254e-01,  6.2419e-01, -2.9057e-01,\n",
      "          -7.6354e-01,  3.1866e-01, -1.3918e+00,  6.0533e-01, -8.8558e-01,\n",
      "          -1.5279e+00,  1.0739e+00,  1.8685e-01, -1.4959e+00,  2.2606e-01,\n",
      "          -1.1700e+00, -6.9934e-01, -1.2621e+00, -1.5290e+00,  7.7954e-01,\n",
      "           8.9885e-01, -2.5701e-01,  1.0962e-01, -5.2366e-01,  5.9997e-01,\n",
      "          -1.4467e+00, -1.6491e+00, -1.2962e+00, -1.5717e+00, -7.9592e-02,\n",
      "          -5.4481e-01,  6.5579e-01,  1.2320e-01,  9.6371e-01, -1.0489e+00,\n",
      "           8.8774e-01,  5.1071e-01,  5.4392e-01, -5.1970e-02, -2.5076e-01,\n",
      "          -1.2989e+00, -1.1172e+00,  1.2922e+00, -7.2315e-01,  1.0262e+00,\n",
      "          -3.6393e-01,  7.8381e-02,  4.1246e-01, -3.8374e-01,  3.2304e-01,\n",
      "           9.0941e-01, -5.0551e-01, -7.6539e-01],\n",
      "         [-1.4266e+00, -1.7057e+00, -1.0418e+00, -1.6872e-01, -1.0777e+00,\n",
      "           1.2760e-01,  1.4469e+00,  6.8813e-01, -7.3334e-01, -8.7295e-01,\n",
      "           4.7670e-01,  6.0812e-01, -3.5256e-01,  2.6280e-01, -5.9452e-01,\n",
      "           1.9267e-01,  1.0602e+00, -1.2642e+00, -3.2924e-01,  1.6919e-01,\n",
      "          -2.9990e-01,  8.2989e-01, -9.5811e-01,  2.8542e-01,  5.2244e-01,\n",
      "           5.2572e-01, -9.2612e-01, -4.3672e-01,  6.9682e-01, -5.6645e-01,\n",
      "           8.5323e-01,  3.8203e-01, -6.0874e-01,  2.3100e-01, -1.0300e+00,\n",
      "           8.9788e-01, -8.7396e-01, -1.0575e+00,  2.2653e-01, -1.4567e+00,\n",
      "          -4.3389e-01,  2.1325e+00,  1.0392e+00,  2.5148e-01,  5.3715e-01,\n",
      "           1.2546e+00,  1.1287e+00, -2.2605e+00,  2.7116e-01,  2.5322e-01,\n",
      "           3.1833e-01, -1.6055e+00,  1.5365e+00, -4.6843e-01, -1.2627e+00,\n",
      "          -5.1087e-01, -1.4528e+00,  1.5218e+00, -6.6484e-02, -3.7984e-01,\n",
      "          -2.7756e-01,  1.1088e+00,  2.5738e-01, -1.1319e+00,  5.5200e-01,\n",
      "          -1.5566e-01, -1.3285e+00, -1.0731e+00,  3.7286e-02,  4.0673e-01,\n",
      "          -2.5715e-01, -1.1293e-02,  1.1675e+00,  7.1857e-01, -1.2214e+00,\n",
      "           8.2138e-01, -5.5146e-01,  1.2967e+00, -4.0994e-01,  4.9155e-01,\n",
      "           2.5996e+00,  5.1409e-01, -1.2314e+00, -2.9687e-01, -5.0846e-03,\n",
      "          -1.1066e+00, -6.6479e-01, -7.3025e-01,  5.6353e-01,  4.7338e-01,\n",
      "           1.3239e+00, -1.4558e+00,  2.4155e-01, -9.0037e-01, -7.0333e-01,\n",
      "          -8.8156e-01, -2.2840e+00, -4.9120e-01,  4.4438e-01, -5.8616e-01,\n",
      "          -4.9917e-01,  1.1577e+00, -4.7858e-02, -1.1127e-01,  9.4098e-01,\n",
      "           1.8423e+00, -3.6438e-01, -4.0933e-01, -1.5329e+00, -7.1106e-01,\n",
      "           6.5936e-01, -9.2590e-01, -8.0862e-01,  1.7632e+00,  2.2816e-01,\n",
      "           9.6980e-01,  4.2962e-01, -4.2070e-01,  1.0173e-01,  1.2261e+00,\n",
      "          -4.7601e-01,  6.3256e-01, -5.4924e-01,  7.5713e-01,  3.6515e-01,\n",
      "          -4.9008e-01, -7.1491e-01,  2.3635e-01],\n",
      "         [-4.1672e-01, -2.4647e-01,  2.4313e+00,  5.9434e-01, -1.0338e+00,\n",
      "           3.4172e-01, -1.7475e+00, -3.2675e-01, -8.4683e-02, -1.8401e-02,\n",
      "           2.6040e-01,  6.5659e-01, -5.2399e-01,  1.9636e+00, -5.8572e-01,\n",
      "           5.8008e-01, -1.3016e+00,  1.7846e+00, -8.8921e-01,  4.0752e-01,\n",
      "           1.1608e+00,  1.0410e+00, -8.5718e-01,  3.4860e-01,  8.4188e-01,\n",
      "           7.4461e-01,  3.9893e-01, -1.6215e-01, -8.6803e-01,  5.9799e-01,\n",
      "          -1.5341e+00, -1.5834e+00,  1.1198e+00,  2.2377e-01, -6.4566e-01,\n",
      "          -1.1923e+00, -5.5145e-01, -9.5865e-01,  2.7022e-01, -5.6356e-02,\n",
      "           1.4749e+00,  1.3091e-01,  7.4528e-01, -1.0033e+00,  1.8982e+00,\n",
      "           9.7335e-01,  6.5819e-01, -1.6138e+00, -1.8888e-02, -1.9097e-01,\n",
      "          -9.4929e-01,  1.1210e+00, -8.8458e-03,  1.1274e+00, -1.2651e-01,\n",
      "           7.0617e-01,  3.5929e-01, -4.1082e-01, -1.9783e+00, -1.8733e+00,\n",
      "          -6.4656e-01,  2.6143e+00, -5.1983e-01,  8.3944e-01,  1.0831e+00,\n",
      "           1.6376e+00, -5.0547e-01, -8.5915e-01,  8.5712e-01,  4.9569e-01,\n",
      "           1.6314e+00,  1.3756e+00, -1.0570e+00,  2.2434e+00,  5.0248e-01,\n",
      "          -1.6154e+00,  5.7553e-01, -2.2095e+00, -8.8385e-01, -5.9777e-01,\n",
      "           1.5466e+00,  8.7998e-01, -1.3715e+00,  1.3082e+00, -1.8955e-01,\n",
      "           2.1487e-02,  7.9105e-01,  6.4255e-01,  9.9852e-01,  3.1610e-01,\n",
      "           4.2278e-01,  8.2373e-01,  1.1611e+00,  1.0425e+00, -1.6920e+00,\n",
      "           1.9171e+00,  4.8955e-01, -9.8692e-01, -3.9334e-01, -2.9632e-01,\n",
      "          -8.1994e-01,  1.0216e+00,  9.1443e-01, -1.4304e+00,  4.0676e-01,\n",
      "           2.8197e-01,  1.7153e-01,  8.4075e-01,  1.1033e+00, -5.9502e-01,\n",
      "          -1.6386e-01, -7.3049e-01,  4.2928e-02, -5.2304e-01,  4.9038e-01,\n",
      "          -5.4214e-01,  1.2261e+00, -8.4592e-01,  2.1946e+00,  1.2251e+00,\n",
      "           4.3408e-01, -4.4749e-01,  1.7606e+00,  1.5740e+00,  1.1316e+00,\n",
      "          -7.5623e-01, -1.4291e+00, -2.4154e+00]],\n",
      "\n",
      "        [[ 2.0225e-01, -8.5456e-01,  5.3135e-01,  1.7506e-01, -9.6576e-02,\n",
      "           1.2438e+00,  8.1631e-01, -2.0651e+00,  1.4676e+00, -2.0958e-01,\n",
      "          -1.4986e+00, -3.3306e-02, -2.0932e+00, -1.1318e+00, -9.0363e-01,\n",
      "           1.6311e-01, -6.1284e-02,  1.0663e+00, -2.1477e+00,  9.8030e-01,\n",
      "          -6.8424e-02, -9.2003e-01,  4.0188e-01, -1.8255e-01, -1.1977e+00,\n",
      "          -1.2461e+00,  1.6105e+00,  4.5688e-01, -4.8541e-03, -5.6734e-01,\n",
      "          -4.6206e-01, -3.6444e-01,  1.2616e+00, -1.2581e+00,  8.2973e-01,\n",
      "          -1.1962e+00, -1.9952e+00, -1.0930e+00, -2.0138e+00,  2.8918e-01,\n",
      "           4.7978e-01,  4.9463e-01,  3.2251e-01,  2.5510e-01, -9.3475e-02,\n",
      "           9.6159e-01,  8.6208e-01,  2.7944e-01, -7.9468e-01,  1.2145e+00,\n",
      "           1.5149e+00,  7.7707e-01,  2.2258e-01, -9.4362e-01,  2.1125e+00,\n",
      "           9.4692e-01,  7.7797e-01, -7.3635e-01, -2.9034e-01,  6.4347e-01,\n",
      "          -2.1383e+00,  3.5840e-01, -4.2970e-01, -7.1722e-01, -4.1122e-01,\n",
      "           6.6832e-01, -6.6633e-02, -8.9469e-01, -1.4649e+00, -3.0903e-01,\n",
      "          -2.2159e-01, -2.7508e-01, -6.9419e-01,  5.3624e-01,  5.6863e-01,\n",
      "           1.8886e+00, -3.6649e-01,  4.3527e-01, -4.2621e-01, -1.2072e+00,\n",
      "          -3.6206e-01, -1.4053e+00, -1.2681e+00,  2.0454e+00,  3.4534e-01,\n",
      "           6.5675e-01,  1.1830e+00,  1.7079e+00, -7.0175e-01,  9.6567e-01,\n",
      "          -1.3765e+00,  1.8453e+00, -9.5257e-01,  4.6976e-01,  7.1494e-01,\n",
      "          -7.5508e-01,  8.5531e-01, -1.0192e+00, -2.2103e-01,  8.2671e-01,\n",
      "           9.1749e-01, -8.1409e-01, -1.6412e+00,  3.1478e-01, -7.8241e-01,\n",
      "          -1.3326e+00, -7.2150e-01,  1.6181e+00, -3.6540e-01,  1.3000e+00,\n",
      "           2.8783e-01, -4.2402e-01, -9.5549e-01,  1.0064e+00, -4.9149e-01,\n",
      "          -6.9270e-01,  7.2492e-01,  1.2435e+00,  1.9915e+00,  9.6652e-02,\n",
      "           6.4976e-01, -6.7828e-01,  9.2435e-01, -1.4956e+00, -1.4456e+00,\n",
      "           4.9422e-01, -1.6023e-01, -7.0941e-01],\n",
      "         [-1.8015e-01, -2.7391e-01,  2.9010e-01, -2.8711e-01, -1.2127e-02,\n",
      "          -8.0469e-01, -6.8656e-01, -1.0525e+00,  8.4288e-01,  1.6310e+00,\n",
      "           1.8023e+00, -1.1389e+00,  1.0882e+00,  9.5420e-01,  7.6690e-01,\n",
      "           8.7614e-01, -3.3153e-01,  2.6008e+00, -1.3922e+00, -3.8236e-01,\n",
      "           4.5757e-01, -6.2661e-01,  2.4576e+00, -1.5755e-01, -7.5915e-01,\n",
      "           1.1680e-01,  1.0611e+00, -2.3025e+00,  7.2748e-01,  1.2414e+00,\n",
      "          -8.3948e-01, -6.8686e-02, -9.9802e-01,  7.7784e-01, -6.5183e-01,\n",
      "           4.0303e-01,  5.2721e-01,  2.1901e-01, -4.0998e-01,  1.3504e+00,\n",
      "          -3.9529e-01,  7.1901e-02, -2.3618e-01, -1.2167e+00, -5.9210e-01,\n",
      "           3.1674e-01, -1.9163e-01, -7.5130e-01, -1.3973e-02,  5.3763e-01,\n",
      "          -6.3651e-01,  2.5295e+00,  1.9907e+00,  2.1169e-01, -1.9219e-01,\n",
      "          -3.0854e-01, -1.1556e-01,  1.0976e+00,  3.2604e-01, -2.3613e+00,\n",
      "          -5.0139e-01,  1.1742e+00,  1.0210e+00,  4.1229e-01, -1.0435e+00,\n",
      "           7.5880e-02,  2.8387e-01, -7.8602e-02, -1.2362e+00,  1.1807e+00,\n",
      "           2.1753e-01, -2.7025e-01, -6.4811e-01,  1.5024e+00,  2.6254e-01,\n",
      "          -6.4317e-01,  6.2039e-01,  4.5965e-01, -1.7423e+00,  4.8375e-01,\n",
      "          -1.3037e+00,  8.6253e-01, -7.1248e-01, -3.0289e-01, -1.1389e-01,\n",
      "          -1.6764e+00,  1.8839e+00,  2.5871e-01, -1.5975e+00, -1.6119e-01,\n",
      "          -3.0756e-01,  4.3179e-01,  2.0039e-01,  4.4849e-01,  4.8299e-01,\n",
      "          -1.0947e+00,  1.2063e-01, -7.6790e-01, -1.5429e+00,  1.0515e+00,\n",
      "          -2.4375e+00,  1.1360e+00,  6.6825e-02, -1.1127e+00, -9.7481e-01,\n",
      "          -7.9246e-01, -8.2045e-01,  7.9880e-01,  1.6305e+00,  2.6784e-01,\n",
      "           2.6619e+00,  1.5806e-01,  1.1706e+00, -1.1268e+00, -8.8876e-01,\n",
      "           8.0451e-01, -7.9112e-01,  9.5852e-02,  1.2632e+00, -3.2705e-01,\n",
      "           7.6279e-01,  2.2361e-02, -3.6006e-01, -8.6871e-01, -8.8048e-01,\n",
      "          -3.6106e-01,  1.2334e-01, -2.0240e-01],\n",
      "         [ 8.9771e-01,  8.2608e-01,  3.7211e-01,  4.0948e-01, -3.1440e-01,\n",
      "          -2.0566e+00, -1.1625e+00,  2.6644e-01, -3.0322e-01,  1.0152e+00,\n",
      "          -1.3445e-01, -7.3434e-01, -3.8485e-01, -1.6923e-01, -8.2011e-01,\n",
      "           8.0463e-01, -1.0573e-03, -9.3249e-01, -6.7766e-01, -1.5333e+00,\n",
      "           3.6837e-01,  9.3902e-01, -1.6355e-01,  1.7939e+00, -1.0796e+00,\n",
      "          -2.0722e-02, -3.2511e-01, -6.1638e-02, -1.6822e+00, -4.0983e-01,\n",
      "           1.1654e+00, -5.5445e-01,  7.4489e-01, -2.4716e-01, -2.9345e-02,\n",
      "           9.5332e-01,  2.2396e+00, -5.1427e-01,  1.4205e+00, -1.6834e+00,\n",
      "           5.7511e-02,  1.0571e+00, -1.7289e+00, -5.8442e-02, -4.0171e-01,\n",
      "          -4.0280e-01,  1.1629e+00,  1.0887e-01,  1.2954e+00, -1.1781e+00,\n",
      "           4.6820e-01,  3.2105e-01,  1.6027e+00,  4.0525e-01,  5.8958e-01,\n",
      "          -1.2001e+00,  2.0491e-01,  2.0205e+00,  1.1829e+00,  9.5363e-01,\n",
      "           3.7960e-02,  1.7963e-01, -2.8171e-01, -2.1611e+00,  1.0459e+00,\n",
      "          -1.9010e-01, -1.7620e+00,  2.0144e+00, -1.2023e+00, -2.5483e-01,\n",
      "          -1.4440e-01, -4.9730e-01, -4.3593e-02,  5.3078e-02, -1.1244e-01,\n",
      "           1.0436e+00, -7.8242e-01, -1.3415e-01, -1.0728e-01,  2.1188e+00,\n",
      "          -1.6916e+00, -4.3733e-01,  5.8158e-01, -5.5129e-01,  1.2129e+00,\n",
      "          -2.3932e+00, -1.1103e+00,  6.8501e-01, -7.6163e-01,  1.3659e+00,\n",
      "          -7.0518e-01,  7.7684e-01,  1.3790e+00,  5.2650e-01,  9.2253e-01,\n",
      "          -3.3103e-01, -2.9495e-01,  1.8749e-01, -2.6792e-01,  1.4720e-01,\n",
      "          -1.9941e-01,  4.4874e-01,  6.0526e-01, -1.4076e-01, -2.2255e-01,\n",
      "           1.3559e+00,  1.0442e+00,  6.4227e-01,  1.2693e+00,  1.2172e-02,\n",
      "          -1.5313e-01,  1.1066e+00, -4.6445e-01, -9.3783e-01,  1.0548e+00,\n",
      "           1.0749e+00,  5.2972e-01, -3.5405e-01, -2.9428e-01,  1.1695e+00,\n",
      "           1.1562e+00, -3.9703e-01,  5.7758e-01, -3.5632e-01, -1.0919e-01,\n",
      "          -1.0804e+00, -1.3522e-01,  9.1415e-01]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "embedding_size = 128\n",
    "embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "input_tokens = torch.tensor([[1, 4, 2], [3, 0, 5]])\n",
    "embeddings = embedding(input_tokens)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef12d121",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6081e+00, -5.2491e-01, -1.0215e+00,  ..., -8.5316e-01,\n",
      "          -1.2378e+00,  1.3094e+00],\n",
      "         [ 7.2766e-01, -8.1402e-01,  1.2481e+00,  ...,  3.4231e-01,\n",
      "           1.9388e+00,  4.8365e-02],\n",
      "         [ 1.7458e-01, -1.3275e+00,  8.7460e-01,  ...,  1.5677e+00,\n",
      "           5.7695e-01, -6.0695e-01],\n",
      "         ...,\n",
      "         [-3.3355e-01, -1.7720e+00,  9.2804e-01,  ...,  5.8213e-01,\n",
      "          -4.7191e-01,  1.0192e+00],\n",
      "         [-2.4009e-01, -3.0194e-02, -1.6326e-01,  ...,  1.3162e+00,\n",
      "           2.8604e+00, -1.0205e+00],\n",
      "         [-1.7223e-02,  1.6216e-01,  1.4983e+00,  ..., -1.2546e+00,\n",
      "           1.2675e-01,  5.8488e-01]],\n",
      "\n",
      "        [[-1.6182e+00, -3.9983e-01, -5.6120e-01,  ..., -1.1844e+00,\n",
      "          -4.7705e-01, -4.0962e-01],\n",
      "         [-3.4997e-01, -1.8715e+00,  1.3966e+00,  ..., -5.2869e-02,\n",
      "           1.2092e+00,  1.1818e+00],\n",
      "         [-2.2094e-01, -1.9799e+00,  4.1086e-01,  ...,  1.3935e+00,\n",
      "           9.0611e-01,  3.8902e-01],\n",
      "         ...,\n",
      "         [-4.3519e-01, -6.2354e-01,  1.5949e+00,  ..., -1.2600e+00,\n",
      "           7.5479e-01, -7.0857e-01],\n",
      "         [-8.2913e-01,  1.2399e+00, -2.1610e-01,  ...,  1.1434e-01,\n",
      "           1.7464e+00, -3.9036e-01],\n",
      "         [-2.3907e-02, -8.9963e-01,  2.6963e+00,  ...,  2.9190e-01,\n",
      "           5.5875e-01, -2.2312e+00]],\n",
      "\n",
      "        [[-1.4436e+00,  3.9411e-01, -5.2712e-01,  ..., -9.4257e-01,\n",
      "          -3.4189e-01,  5.4730e-01],\n",
      "         [ 1.9576e-01,  5.4251e-01,  1.5389e+00,  ..., -8.1959e-01,\n",
      "          -5.4482e-01,  2.1013e+00],\n",
      "         [-5.2028e-01, -1.1443e-01, -5.7556e-01,  ...,  1.1361e+00,\n",
      "           5.4073e-01, -4.5632e-01],\n",
      "         ...,\n",
      "         [ 8.2532e-01, -5.3150e-01,  1.0838e+00,  ..., -1.5703e+00,\n",
      "           1.1236e+00,  4.5284e-02],\n",
      "         [ 5.2627e-02,  3.2917e-01,  4.5904e-01,  ...,  3.3032e-01,\n",
      "           1.6836e+00, -4.9867e-01],\n",
      "         [-4.2023e-01, -1.9160e+00,  1.4473e+00,  ...,  3.9520e-01,\n",
      "           1.2258e+00, -1.4655e-01]],\n",
      "\n",
      "        [[-7.0959e-01, -9.0736e-01, -7.8888e-01,  ...,  8.2065e-01,\n",
      "          -2.2444e+00,  8.0230e-01],\n",
      "         [ 8.2195e-01, -6.6811e-01,  1.7415e+00,  ...,  6.5769e-01,\n",
      "           1.6546e+00, -3.1463e-01],\n",
      "         [ 3.8509e-01, -6.3170e-01,  2.0871e-02,  ...,  8.6275e-01,\n",
      "           6.7254e-01,  3.4172e-01],\n",
      "         ...,\n",
      "         [-1.1638e+00, -1.5380e+00,  5.9855e-01,  ..., -2.4769e-01,\n",
      "           3.5721e-01,  1.5939e+00],\n",
      "         [-2.0204e-01,  8.4807e-01,  6.6810e-01,  ...,  4.3563e-01,\n",
      "           1.2923e+00, -2.4885e+00],\n",
      "         [ 8.2898e-02, -1.9820e+00,  2.2015e+00,  ..., -8.0578e-02,\n",
      "           1.8902e-02, -2.5036e+00]],\n",
      "\n",
      "        [[-4.7945e-01, -1.7436e+00, -2.5080e+00,  ..., -4.8083e-01,\n",
      "           4.4371e-01, -3.3681e-01],\n",
      "         [ 2.5015e-03,  3.8996e-01,  1.3838e+00,  ..., -1.1777e-01,\n",
      "           1.2904e+00,  4.7917e-02],\n",
      "         [-8.0622e-01, -1.9427e+00, -4.8923e-01,  ...,  1.8844e-01,\n",
      "          -2.0727e-01,  7.1837e-01],\n",
      "         ...,\n",
      "         [-3.1063e-01, -3.5834e-01,  7.3404e-01,  ..., -1.5650e+00,\n",
      "           4.9328e-01,  4.9296e-01],\n",
      "         [-7.6780e-01,  2.9391e-01,  1.4358e+00,  ...,  3.8621e-01,\n",
      "           1.1437e+00, -1.6871e+00],\n",
      "         [-1.4167e+00, -9.9791e-01,  1.6595e+00,  ..., -1.0006e+00,\n",
      "          -2.0897e-02, -1.8661e+00]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_dim = 100\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "encoder = TransformerEncoder(input_dim, hidden_dim, num_layers, num_heads)\n",
    "x = torch.randint(0, input_dim, (5, 10))\n",
    "output = encoder(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9194aab3",
   "metadata": {},
   "source": [
    "# DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5517ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(1000, hidden_dim)\n",
    "        self.layers = nn.ModuleList([nn.TransformerDecoderLayer(hidden_dim, num_heads)\n",
    "                                     for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, encoder_output):\n",
    "        x = self.embedding(x)\n",
    "        positions = torch.arange(x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = x + self.pos_embedding(positions)    \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99153697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 100\n",
    "output_dim = 100\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "num_heads = 4\n",
    "encoder = TransformerEncoder(input_dim, hidden_dim, num_layers, num_heads)\n",
    "decoder = TransformerDecoder(output_dim, hidden_dim, num_layers, num_heads)\n",
    "x = torch.randint(0, input_dim, (5, 10))\n",
    "encoder_output = encoder(x)\n",
    "y = torch.randint(0, output_dim, (5, 10))\n",
    "output = decoder(y, encoder_output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881d611",
   "metadata": {},
   "source": [
    "# ENCODER & DECODER LAYER IN PYTORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2277c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        self.encoder_embedding = nn.Embedding(input_dim, hidden_dim)\n",
    "        self.decoder_embedding = nn.Embedding(output_dim, hidden_dim)\n",
    "        self.encoder_pos_embedding = nn.Embedding(1000, hidden_dim)\n",
    "        self.decoder_pos_embedding = nn.Embedding(1000, hidden_dim)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(hidden_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            nn.TransformerDecoderLayer(hidden_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, encoder_input, decoder_input):\n",
    "        encoder_embedded = self.encoder_embedding(encoder_input)\n",
    "        decoder_embedded = self.decoder_embedding(decoder_input)\n",
    "        encoder_positions = torch.arange(encoder_input.size(1),\n",
    "                                         device=encoder_input.device).unsqueeze(0)\n",
    "        decoder_positions = torch.arange(decoder_input.size(1), \n",
    "                                         device=decoder_input.device).unsqueeze(0)\n",
    "        encoder_embedded = encoder_embedded + self.encoder_pos_embedding(encoder_positions)\n",
    "        decoder_embedded = decoder_embedded + self.decoder_pos_embedding(decoder_positions)\n",
    "        for layer in self.encoder_layers:\n",
    "            encoder_embedded = layer(encoder_embedded)\n",
    "        encoder_output = encoder_embedded\n",
    "        for layer in self.decoder_layers:\n",
    "            decoder_embedded = layer(decoder_embedded, encoder_output)\n",
    "        output = self.fc(decoder_embedded)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e1d987",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "adefc3a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39108/4240968889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBucketIterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mSRC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spacy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mTRG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"spacy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<sos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<eos>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sequential, use_vocab, init_token, eos_token, fix_length, dtype, preprocessing, postprocessing, lower, tokenize, tokenizer_language, include_lengths, batch_first, pad_token, unk_token, pad_first, truncate_first, stop_words, is_target)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# in case the tokenizer isn't picklable (e.g. spacy)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minclude_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torchtext/data/utils.py\u001b[0m in \u001b[0;36mget_tokenizer\u001b[0;34m(tokenizer, language)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spacy\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mspacy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_spacy_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# set library-specific custom warning handling before doing anything else\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msetup_default_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/errors.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mErrorsWithCodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/spacy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"Helpers for Python and platform compatibility.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/thinc/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mabout\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/thinc/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConfigValidationError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPromise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVARIABLE_RE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/thinc/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_cupy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_cupy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/thinc/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Bring in subpackages.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_ragged_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatching\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdense_to_sparse_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/service/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    417\u001b[0m \"\"\"\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_dataset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_service_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/data_service_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_service_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompression_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_server_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/compression_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Ops for compressing and uncompressing dataset elements.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_experimental_dataset_ops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mged_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwrapt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/util/nest.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \"\"\"\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse_tensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sparse_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoc_controls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0m_np_bfloat16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_bfloat16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_bfloat16_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0m_np_float8_e4m3fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_float8_e4m3fn_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0m_np_float8_e5m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pywrap_float8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_float8_e5m2_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "SRC = Field(tokenize=\"spacy\", tokenizer_language=\"fr\", init_token=\"<sos>\", eos_token=\"<eos>\", \n",
    "            lower=True)\n",
    "TRG = Field(tokenize=\"spacy\", tokenizer_language=\"en\", init_token=\"<sos>\", eos_token=\"<eos>\", \n",
    "            lower=True)\n",
    "train_data, valid_data, test_data = Multi30k.splits(exts=(\".fr\", \".en\"), fields=(SRC, TRG))\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 3\n",
    "NUM_HEADS = 8\n",
    "model = Transformer(INPUT_DIM, OUTPUT_DIM, HIDDEN_DIM, NUM_LAYERS, NUM_HEADS)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TRG.vocab.stoi[TRG.pad_token])\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    datasets=(train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    ")\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeafd9",
   "metadata": {},
   "source": [
    "# TEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f22a0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def translate_sentence(model, sentence, src_field, trg_field, max_len=50):\n",
    "    model.eval()\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token.text.lower() for token in spacy_fr(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encoder(src_tensor, src_mask)\n",
    "    \n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "    \n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0)\n",
    "        \n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        print(trg_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
